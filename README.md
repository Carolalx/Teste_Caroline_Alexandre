# ğŸ¥ Teste_ANS â€“ IntegraÃ§Ã£o com API PÃºblica da ANS

[![Python](https://img.shields.io/badge/python-3.12-blue)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-10%2B-blue)](https://www.postgresql.org/)

> ImplementaÃ§Ã£o das Etapas 1, 2 e 3 do teste tÃ©cnico da ANS: integraÃ§Ã£o com API pÃºblica, normalizaÃ§Ã£o, consolidaÃ§Ã£o, validaÃ§Ã£o, enriquecimento e anÃ¡lise de dados.

---

## **ğŸ“‹ DescriÃ§Ã£o do Projeto**

Este projeto implementa um pipeline de processamento de dados (ETL) dividido em trÃªs etapas fundamentais:

1. **IntegraÃ§Ã£o com API da ANS (Etapa 1)**
   - Download automatizado dos arquivos ZIP referentes aos Ãºltimos 3 trimestres disponÃ­veis.
   - ExtraÃ§Ã£o e normalizaÃ§Ã£o dinÃ¢mica de colunas (tratando variaÃ§Ãµes como `REG_ANS` vs `RegistroANS`).
   - ConsolidaÃ§Ã£o de mais de **2,1 milhÃµes de registros** em um Ãºnico CSV.

2. **TransformaÃ§Ã£o e AgregaÃ§Ã£o (Etapa 2)**
   - **Enriquecimento:** Cruzamento de dados financeiros com a base cadastral oficial da ANS via `RegistroANS`.
   - **Saneamento:** Tratamento de escala decimal e valores nulos.
   - **CÃ¡lculo EstatÃ­stico:** GeraÃ§Ã£o de mÃ©tricas de Total de Despesas, MÃ©dia Trimestral e Desvio PadrÃ£o por Operadora e UF.
   - **Resultados:** GeraÃ§Ã£o do arquivo `despesas_agregadas.csv` e compactaÃ§Ã£o final no ZIP solicitado.

3. **Banco de Dados e AnÃ¡lise SQL (Etapa 3)**
   - Modelagem relacional no **PostgreSQL** utilizando o modelo Estrela (*Star Schema*).
   - ImplementaÃ§Ã£o de integridade referencial flexÃ­vel para comportar inconsistÃªncias nativas da fonte.
   - Scripts de carga e queries analÃ­ticas para insights de mercado.

---

## **ğŸ›  Tecnologias e Bibliotecas**

- **Linguagem:** Python 3.12
- **Bibliotecas:** `pandas`, `requests`, `beautifulsoup4`, `urllib3`
- **Banco de Dados:** PostgreSQL > 10
- **Modelagem:** Relacional com Chaves Estrangeiras (FK)

---

## **ğŸ“‚ Estrutura de Pastas**

```text
Teste_ANS/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py           # IngestÃ£o (Etapa 1)
â”‚   â”œâ”€â”€ transform.py      # Enriquecimento e AgregaÃ§Ã£o (Etapa 2)
â”‚   â””â”€â”€ utils.py          # FunÃ§Ãµes auxiliares e validaÃ§Ãµes
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ create_tables.sql # DDL para criaÃ§Ã£o das tabelas
â”‚   â”œâ”€â”€ load_data.sql     # Comandos de correÃ§Ã£o de escala e Ã­ndices
â”‚   â””â”€â”€ analytics.sql     # Queries analÃ­ticas solicitadas
â”‚
â”œâ”€â”€ data/                 # Pasta local para armazenamento de CSVs (ignorada pelo Git)
â”‚
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â”œâ”€â”€ .gitignore            # Filtro de arquivos para o repositÃ³rio
â””â”€â”€ README.md             # DocumentaÃ§Ã£o do projeto
```

---

## **ğŸš€ Como Executar**

1. Criar virtual environment:

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

```


2. Processamento de Dados:

```bash
python src/etapa1_ingestao.py
python src/etapa2_enriquecimento.py
```


3. Banco de Dados:
    - Execute o script db/create_tables.sql no seu cliente PostgreSQL.
    - Realize a importaÃ§Ã£o dos CSVs (Cadastro primeiro, depois Despesas).
    - Execute os UPDATEs de correÃ§Ã£o de escala contidos no db/load_data.sql.

**O CSV consolidado serÃ¡ gerado em:**
`data/consolidado/consolidado_despesas.zip`

## ğŸ’¡ DecisÃµes TÃ©cnicas e Trade-offs

- **Tratamento de inconsistÃªncias:**
    Durante a carga, identificou-se que 11 operadoras (ex: Registro 350141) possuÃ­am lanÃ§amentos financeiros mas nÃ£o constavam no cadastro de "Ativas". Optou-se pelo uso de LEFT JOIN e remoÃ§Ã£o de CONSTRAINTS rÃ­gidas para garantir que nenhum dado financeiro fosse perdido.
- **CorreÃ§Ã£o de Escala Decimal:** 
    Devido ao comportamento de importaÃ§Ã£o de alguns clientes SQL que ignoram o separador decimal, foi aplicado um saneamento via SQL (SET valor = valor / 100) para garantir a precisÃ£o dos trilhÃµes para a escala correta de milhÃµes/bilhÃµes.
- **Performance:** 
    Performance: O processamento em Python utiliza o pandas com mapeamento de tipos otimizados, permitindo o tratamento de milhÃµes de linhas em segundos em hardware convencional.

## ğŸ“Š Resultados Finais

- **Total de registros processados: 2.163.924** 
- **Operadoras cadastradas: 1.110**
- **Integridade: Dados financeiros 100% preservados, incluindo contas com valores negativos (estornos contÃ¡beis).** 



## ğŸ‘©â€ğŸ’» Autora
- Caroline Alexandre  
- [GitHub](https://github.com/Carolalx)